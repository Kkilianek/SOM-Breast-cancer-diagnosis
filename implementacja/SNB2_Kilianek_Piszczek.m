%% Kacper Kilianek (305375), Adam Piszczek (303803) [zespÃ³Å‚ nr. 22]
% Sieci neuronowe w zastosowaniach biomedycznych (SNB) â€“ Projekt
% Projekt nr. 36: Diagnostyka raka piersi w badaniach mammograficznych za pomocÄ… sieci SOM (katalog: Mammographic Mass_MLR)

%% ========= Przygotowanie Å›rodowiska =========

clear;
clc;
close all;

%% ========= Wczytanie danych =========

% Dane wczytane sÄ… w kolejnych kolumnach BI-RADS,Age,Shape,Margin,Density,Severity
try
    M = readtable('mammographic_masses.data.txt'); % przekonwertowanie plikÃ³w na txt
catch 
    fprintf("Nie udaÅ‚o siÄ™ otworzyÄ‡ pliku mammographic_masses.data.txt")
end

%% ========= Preprocessing danych (etap 1) =========

size1 = size(M,1); % zapisanie iloÅ›ci wektorÃ³w cech przed preprocessingiem
M = table2array(M); % zamiana na dane numeryczne

% Proponowany sposÃ³b kodowania danych numerycznych -> single
% (single-precision number), poniewaÅ¼ mamy do czynienia z liczbami 
% caÅ‚kowitymi typu integer
single(M); 

% usuniÄ™cie zÅ‚ych danych pierwszej cechy (BI-RADS) z poza zdefiniowanego zakresu 1-5
% ustawienie warunkÃ³w pilnujÄ…cych podane zakresy cech:

% Pierwszy wektor cech (BI-RADS):
Cond1 = M(:,1) > 5;
Cond2 = M(:,1) < 1; 
Condition1 = Cond1 | Cond2; % poÅ‚aczenie warunkÃ³w

% Trzeci wektor cech (KsztaÅ‚t):
Cond1 = M(:,3) > 4;
Cond2 = M(:,3) < 1; 
Condition2 = Cond1 | Cond2; 

% Czwarty wektor cech (Margines):
Cond1 = M(:,4) > 5;
Cond2 = M(:,4) < 1; 
Condition3 = Cond1 | Cond2; 

% Trzeci wektor cech (GÄ™stoÅ›Ä‡):
Cond1 = M(:,5) > 4;
Cond2 = M(:,5) < 1; 
Condition4 = Cond1 | Cond2; 

Conditions = Condition1 | Condition2 | Condition3 | Condition4;
M(Conditions,:) = []; 
size2 = size(M,1); % wielkoÅ›Ä‡ macierzy po redukcji bÅ‚Ä™dnych wektorÃ³w
numOfDeletedRows = size1 - size2; % iloÅ›Ä‡ danych, ktÃ³re zostaÅ‚y usuniÄ™te

%% ========= Preprocessing danych (etap 2) =========

% PodziaÅ‚ danych na zÅ‚oÅ›liwe i Å‚agodne, tak aby przedstawiÄ‡ histogramy cech
% w klasach, ktÃ³re sÄ… klasyfikowane
M = sortrows(M,6);
malignant = M(:,6) == 1;
benign = M(:,6) == 0;
Malignant = M(malignant,:); % zbiÃ³r cech dla przypadku nowotworu zÅ‚oÅ›liwego
Benign = M(benign,:); % zbiÃ³r cech dla przypadku nowotworu Å‚agodnego

%% ========= Preprocessing danych (etap 3) =========

% Przed podaniem danych wejÅ›ciowych do sieci neuronowej musimy jeszcze
% przeprowadziÄ‡ operacjÄ™ normalizacji, tak aby kaÅ¼da z cech miaÅ‚a
% identyczny wpÅ‚yw na proces uczenia siÄ™ sieci. JeÅ¼eli nie dokonalibyÅ›my
% takich operacji, to jedna z cech (w naszym przypadku wektorWagyczÄ…ca wieku),
% miaÅ‚aby najwiÄ™kszy wpÅ‚yw na rozkÅ‚ad danych, przez to, Å¼e jej rozpiÄ™toÅ›Ä‡
% jest najwiÄ™ksza wynoszÄ…ca od 18 do 96 lat. Dlatego teÅ¼ poniÅ¼ej
% dokonaliÅ›my przeksztaÅ‚ceÅ„ tak aby kaÅ¼da cecha przyjmowaÅ‚a wartoÅ›ci w
% zakresie od 0 do 1.

% Zgodnie ze wzorem ÅºrÃ³dÅ‚o: http://lh3.ggpht.com/_MrdHIr826C4/Sl7eVpJOYfI/AAAAAAAAB34/MCFvz1r_CZQ/s800/7.JPG
M(:,1) = (M(:,1)-min(M(:,1)))/(max(M(:,1)-min(M(:,1)))) * (1-0) + 0;
M(:,2) = (M(:,2)-min(M(:,2)))/(max(M(:,2)-min(M(:,2)))) * (1-0) + 0;
M(:,3) = (M(:,3)-min(M(:,3)))/(max(M(:,3)-min(M(:,3)))) * (1-0) + 0;
M(:,4) = (M(:,4)-min(M(:,4)))/(max(M(:,4)-min(M(:,4)))) * (1-0) + 0;
M(:,5) = (M(:,5)-min(M(:,5)))/(max(M(:,5)-min(M(:,5)))) * (1-0) + 0;

%% ========= PodziaÅ‚ danych na zbiÃ³r uczÄ…cy i zbior testowy =========

zbiorTestowy = [Malignant(1:uint64(size(Malignant,1)/2),:) ; Benign(1:uint64(size(Benign,1)/2),:)]; % dane zbiorTestowyowe
zbiorTreningowy = [Malignant(uint64(size(Malignant,1)/2)+1:size(Malignant,1),:) ; Benign(uint64(size(Benign,1)/2)+1:size(Benign,1),:)]; % dane uczÄ…ce

%% ========= Implementacja sieci SOM =========

liczbaWierszySiatki = 5;
liczbaKolumnSiatki = 5;

iteracja = 15; % OdgÃ³rny limit iteracji potrzebny do zbieÅ¼noÅ›ci

%% =========== Ustawienie parametrÃ³w dla SOM =========
% PoczÄ…tkowy rozmiar sÄ…siedztwa topologicznego zwyciÄ™skiego neuronu
poczatkowyRozmiarSasiedztwa = 1;

% StaÅ‚a czasowa poczÄ…tkowego rozmiaru sÄ…siedztwa topologicznego
% skÄ…d jest wzÃ³r na to - i dlaczego akurat logarytm naturalny? <- ja ten
% kod tak jak mÃ³wiÅ‚em skopiowaÅ‚em z neta (nie mam pojecia skad sa te wzory)
stalaCzasowa = iteracja/log(poczatkowyRozmiarSasiedztwa);

% PoczÄ…tkowa szybkoÅ›Ä‡ uczenia siÄ™ zmienna w czasie
poczatkowyWspolczynnikUczenia = 1;

wspolczynnikNauki = iteracja; % StaÅ‚a czasowa dla zmiennej w czasie szybkoÅ›ci uczenia siÄ™

mapaSOM = inicjalizacjaWag(liczbaWierszySiatki,liczbaKolumnSiatki,size(zbiorTreningowy(:,1:5),2));

rysujDane(zbiorTreningowy(:,1:5),zbiorTreningowy(:,6))

%% =========== Proces uczenia sieci SOM =========

for t = 1:iteracja
    szerokosc = poczatkowyRozmiarSasiedztwa*exp(-t/stalaCzasowa); %tu teÅ¼ skÄ…d ten wzorek wziÄ…Å‚eÅ›? :D <- same
    wariancjaSzerokosci = szerokosc^2;
    wskaznikNauki = poczatkowyWspolczynnikUczenia*exp(-t/wspolczynnikNauki); %again <- same
    if wskaznikNauki <0.025
            wskaznikNauki = 0.1; %czemu tu juÅ¼ taki spadek? <- prawdopodobnie po to by nie byl ten wspolczynnik ultra maly
    end

    [dystansEntropy, indeks] = entropyDistance(zbiorTreningowy(:,1:5), mapaSOM, liczbaWierszySiatki, ...
                                            liczbaKolumnSiatki,size(zbiorTreningowy(:,1:5),1), size(zbiorTreningowy(:,1:5),2));
    [~,pomocnicza] = min(dystansEntropy(:));
    [wygranyRzad,wygranaKolumna] = ind2sub(size(dystansEntropy),pomocnicza);

    % ustalenie sasiedztwa neuronÃ³w
    neighborhood = obliczNajblizszegoSasiada(liczbaWierszySiatki, liczbaKolumnSiatki, wygranyRzad, ...
                                            wygranaKolumna, wariancjaSzerokosci);
    % aktualizacja mapy
    mapaSOM = aktualizacjaWag(zbiorTreningowy(:,1:5), mapaSOM, liczbaWierszySiatki, liczbaKolumnSiatki, ...
                                size(zbiorTreningowy(:,1:5),2), indeks, wskaznikNauki, neighborhood);
    
    % Wektor wagowy neuronu
    wektorWag = zeros(liczbaWierszySiatki*liczbaKolumnSiatki, size(zbiorTreningowy(:,1:5),2));
    % Macierz SOM do rysowania
    macierz = zeros(liczbaWierszySiatki*liczbaKolumnSiatki,1);
    % zmienna pomocnicza
    pomocnicza = 1;  
    figure(1);
    title('Wykres wag')
    hold on;

    % Pobierz wektor wagowy neuronu
    for r = 1:liczbaWierszySiatki
        for c = 1:liczbaKolumnSiatki      
            wektorWag(pomocnicza,:) = reshape(mapaSOM(r,c,:),1,size(zbiorTreningowy(:,1:5),2));
            pomocnicza = pomocnicza + 1;
        end
    end
    
    figure(2)
    title('Proces uczenia sieci (przebieg bÅ‚Ä™du w zaleÅ¼noÅ›ci od liczby iteracji)')
    hold on;
    figure(3)
    title('Mapa SOM')

    % Rysuj siatke SOM
    for r = 1:liczbaWierszySiatki
        rzad1 = 1+liczbaWierszySiatki*(r-1);
        rzad2 = r*liczbaWierszySiatki;
        wiersz1 = liczbaWierszySiatki*liczbaKolumnSiatki;
        figure(2)
        blad = 1;
        scatter(t,blad) % <- tutaj trzeba ogarnÄ…Ä‡ jak rysowaÄ‡ wykres funkcji bÅ‚edu od iteracji
        % prawdopdoobnie trzeba wpasc na pomysl w jaki sposob robimy
        % klasyfikacje zlosliwa/lagodna. W 1 czesci napisalismy cos
        % takiego: decyzja zwiÄ…zana z ustaleniem grupy danego wektora cech jest realizowana na podstawie
        % podobieÅ„stwa wartoÅ›ci zbiorÃ³w. Tworzona jest zmienna decyzyjna ð‘ž, ktÃ³ra w zaleÅ¼noÅ›ci od wartoÅ›ci
        % podobieÅ„stwa wzglÄ™dem caÅ‚ego zbioru danych i jego ð‘ regionÃ³w, wybiera k-tÄ… iloÅ›Ä‡ regionÃ³w i liczony
        % jest wtedy uÅ‚amek ð‘“ð‘š zÅ‚oÅ›liwych regionÃ³w. Ustawiany jest prÃ³g decyzyjny ð¶ð‘“ (z zakresu od 0 do 1), a
        % przypadek dla nowotworu zÅ‚oÅ›liwego egzekwowany jest w przypadku ð‘“ð‘š â‰¥ ð¶ð‘“ (inaczej klasyfikowana jest
        % zmiana Å‚agodna) 
        % ((((Sam to jeszcze sprobuje przemyslec))))
        figure(1)
        macierz(2*r-1,1) = plot(wektorWag(rzad1:rzad2,1),wektorWag(rzad1:rzad2,2),'--ro','LineWidth',2,'MarkerEdgeColor','g','MarkerFaceColor','g','MarkerSize',4);
        macierz(2*r,1) = plot(wektorWag(r:liczbaKolumnSiatki:wiersz1,1),wektorWag(r:liczbaKolumnSiatki:wiersz1,2),'--ro','LineWidth',2,'MarkerEdgeColor','g','MarkerFaceColor','g','MarkerSize',4);
    end

    figure(1)
    hold off
    figure(2)
    hold off
    figure(3)
    title('Mapa SOM')
    [X, Y] = meshgrid(mapaSOM);
    plot(X, Y, '.k')
    axis square
    hold off
end
